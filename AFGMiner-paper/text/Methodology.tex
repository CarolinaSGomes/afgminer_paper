In the experimental evaluation of AFGMiner, the tools HEPMiner and SCPMiner were separately tested in order to analyze the patterns that AFGMiner is able to uncover and how scalable the algorithm is in terms of run-time. Experiments for HEPMiner were performed on an Intel Core 2 Quad CPU Q6600 machine, running at 2.4 GHz and with 3 GB of RAM. The operating system installed in the machine was a Microsoft Windows XP Professional Edition, Service Pack 3. Experiments for SCPMiner ran on an AMD Athlon II Neo K125 running at 1.70 GHz and with 4 GB of RAM, of which 3.75 GB were usable. The operating system installed in the machine was a 64-bit Windows 7 Home Premium, Service Pack 1.

\subsection{HEPMiner Evaluation}
The experimental evaluation of the algorithm in the context of HEPMiner used profiles from the DayTrader Benchmark, running on WebSphere Application Server, on a z196 mainframe and JIT-compiled using the IBM Testarossa JIT compiler. The WebSphere Application Server is a Java\textregistered~Enterprise Edition (JEE) server developed by IBM and written in Java~\cite{WAS}. It has a very flat profile, with its execution time spread relatively evenly over 2,566 methods, as is typical of large business applications. The IBM System z is a generation of mainframe products by IBM~\cite{zEnterprise}. The IBM zEnterprise System 196, or z196 model, is a CISC mainframe architecture with a superscalar, out-of-order pipeline.

AFGMiner-locreg, as used by HEPMiner, had its run-time scalability tested in two experiments, A and B, by running the algorithm on DayTrader methods. Three important parameters that were taken into account in this analysis are the \emph{Minimum Hotness Method} (MMH) value, the minimum support threshold (MinSup) and the maximum allowed size of the attribute set in each candidate pattern node (MaxAttrs). The MMH is calculated by dividing the sum of all CPU cycles associated with each one of DayTrader's profiled methods by the cycles associated with the entire program run. For experiments {\bf A}and {\bf B}, the MMH was kept at 0.001, meaning that only methods with execution time that exceeds 0.1\% of program run-time are selected for mining (\emph{i.e.} in DayTrader, 278 of 2,566).

\emph{Experiment {\bf A}} compared the run-times of AFGMiner-locreg with respect to changes in MaxAttrs. MinSup was kept at 0.001, meaning that only those patterns consuming more than 0.1\% of program run-time are considered heavyweight. The goal was to measure the impact on run-time of attribute set sizes in candidate pattern nodes. The higher the number of attributes allowed, the more candidate patterns can be potentially generated, which is why modifying this parameter is a way of controlling the memory consumed by the algorithm and, we conjectured, also its run-time. \emph{Experiment {\bf B}} compared the run-times of AFGMiner-locreg with respect to changes in the number of EFG nodes visited by the algorithm, by changing MinSup but keeping MaxAttrs at 5.

Patterns found by AFGMiner-locreg were also compared to the ones found by the FlowGSP algorithm, which finds only sub-path patterns in AFGs. FlowGSP was modified to support variations in MMH, MinSup and MaxAttrs, and run on DayTrader methods with the same parameter values used for Experiment {\bf B} above. In addition, an expert compiler engineer from IBM's JIT Compiler Development team verified the usefulness of patterns identified by the HEPMiner tool, as described in Section~\ref{sec:QualAnalysis}.

\subsection{SCPMiner Evaluation}
The experimental evaluation of SCPMiner focused on verifying if the patterns found by the tool are useful to developers (Section~\ref{sec:QualAnalysis}). The benchmarks \emph{bzip2}, \emph{gobmk}, \emph{mcf} and \emph{namd}, all from the SPEC CPU2006~\cite{SPEC} suite, were analyzed by an expert developer from IBM's Multi-core Performance Tooling team, using the source-code of the benchmarks and previous knowledge about them. He compared source-code lines associated with heavyweight pattern occurrences, pointed by SCPMiner, to source lines indicated by an internal IBM tool being developed by the team. This internal tool highlights the source-code lines that consume the most CPU cycles when a program is profiled by \emph{tprof}. The IBM tool is thus only useful when the profile of analyzed applications is not flat. As a consequence, for purposes of validation, the four benchmarks we analyzed do not have flat profiles, so that the results of SCPMiner and the IBM tool could be more easily compared.







