FlowGSP is a sequential-pattern mining algorithm that finds patterns whose occurrences are sub-paths of AFGs.~\cite{JockschCC10}~\cite{FlowGSP}. AFGMiner differs from FlowGSP in that it is able to find not only sequential patterns, but also patterns whose occurrences are sub-graphs of AFGs. AFGMiner takes less time than FlowGSP to find each pattern. In addition, AFGMiner is able to map each pattern to all its occurrences and output this mapping to the user.

gSpan is a classic sub-graph mining algorithm. The main difference between AFGMiner and gSpan is that AFGMiner is able to handle multiple node attributes and has been tailored for directed graphs, although as long as an appropriate sub-graph isomorphism algorithm is used when matching candidate sub-graphs to dataset graphs, it can also work for undirected graphs. Another difference is that AFGMiner uses breadth-first search with eager pruning when generating candidate sub-graphs, while gSpan follows a depth-first approach~\cite{gSpan}. An improved version of gSpan, gRed, modifies the canonical labeling system of gSpan to detect cases where it is guaranteed that a candidate pattern is not frequent, thus eliminating the need to mine for it in the dataset~\cite{gRed}.
 
FSP is based on depth-first search just as gSpan, but it improves its canonical representation and similarities between sibling sub-graphs in order to reduce the number of isomorphism tests. FSP differs from AFGMiner in the same aspects as gSpan does~\cite{FSP}. AGM is another well-known mining algorithm, based on breadth-first search and adjacency matrices, that uses transformation matrices to convert the adjacency matrices of graphs into their canonical form and detect redundant candidates~\cite{AGM}. FFSM, like AGM, uses adjacency matrices. However, it adopts depth-first search when mining for candidate sub-graphs~\cite{FFSM}. Its novelty is the introduction of embeddings that make the mining process faster, even if they increase memory requirements. AFGMiner-locreg also uses embeddings, though its definition of embedding differs from FFSM. In FFSM, an embedding does not take into consideration the edge relations for each occurrence of the sub-graph because mined graphs are undirected. In contrast, AFGMiner has to record the complete mapping between sub-graph patterns and occurrences, which makes the embeddings more memory-consuming.

Gaston is a more recent sub-graph mining algorithm. It is based on the fact that substructures typically mined for in datasets, such as sub-paths, sub-trees, and sub-graphs, are contained in each other. This property allows the search to be split into steps of increasing complexity. A frequent path, tree and graph miner are thus integrated into a single algorithm. Gaston follows the breadth-first approach to search, and, similarly to AFGMiner, was implemented with and without embeddings. In contrast to AFGMiner, however, Gaston only mines for patterns in non-attributed, undirected and unweighted graphs~\cite{Gaston}.

\emph{Borgelt} introduces a family of canonical descriptions of graphs that can be exploited to make frequent sub-graph mining more efficient~\cite{BorgeltCDAKO07}. The canonical descriptions are a generalization of the canonical labeling system used by gSpan and AFGMiner. While AFGMiner's system is defined by a depth-first traversal of the sub-graph, \emph{Borgelt}'s work allows for any systematic way of describing the sub-graph by one of the sub-graph's spanning trees. \emph{Worlein \etal} present a quantitative comparison between classical sub-graph mining algorithms, including the aforementioned gSpan, FFSM and Gaston~\cite{WorleinPKDD05}. According to their study, Gaston is the fastest of the algorithms. However, gSpan, the second-fastest, scales better for larger datasets, which justifies the choice of gSpan as a basis for AFGMiner. 

The work of \emph{Horvart \etal} describes a sub-graph mining algorithm for outerplanar graphs, which are a strict generalization of trees~\cite{HorvathKDD06}. The algorithm runs in incremental polynomial time due to the properties of outerplanar graphs, \ie they are similar enough to trees. This work contrasts with AFGMiner in that it does not handle directed, weighted and attributed graphs. However, similarly to the applications of AFGMiner described in this work, it targets a more tractable class of graphs when mining, and is thus able to run in incremental polynomial time.

The work that inspired the creation of SCPMiner is the code clone detection tool \emph{Deckard} presented by \emph{Jiang \etal}~\cite{Deckard}. The clone detection algorithm created by \emph{Jiang \etal} for Deckard, similarly to SCPMiner, converts the source-code of the program to be analyzed into its AST. The algorithm characterizes sub-trees of the AST as vectors of source-code characteristics that capture structural information about the represented code. It then uses efficient hashing and near-neighbor querying for numerical vectors to cluster such sub-trees into code clones. SCPMiner, analogously, converts the AST into a set of CFGs with source-code characteristics associated with each basic block composing the CFGs, and clusters the blocks as an initial step to find source-code patterns. However, SCPMiner does not use a sophisticated clustering scheme such as Deckard's. Adapting Deckard's clustering scheme to SCPMiner would in all likelihood greatly improve the quality of patterns found by AFGMiner.

A work related to HEPMiner is that of \emph{Dreweke \etal}. It applies sub-graph mining to help compiler developers in their program improvement efforts~\cite{DrewekeCGO07}. The work presents a novel approach to an existing code transformation called procedural abstraction. Procedural abstraction extracts duplicate code segments into a newly created method in order to decrease code size. The approach consists of composing data flow graphs from the target program and mining, using gSpan, for frequent sub-graph patterns that represent the code segments to be extracted. HEPMiner differs from this work in that it is not an interprocedural compiler code transformation, but rather an external performance analysis tool that helps compiler developers to reach conclusions about the performance of applications of interest, and detect improvement opportunities. 
